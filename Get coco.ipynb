{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7ddefb2-9c4d-4df8-abd9-6861b94df861",
   "metadata": {},
   "source": [
    "# Sampling CoCo image dataset to train and use DPM on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6da36d64-6128-45cb-b8d2-2ea7406e4cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from pycocotools.coco import COCO\n",
    "import requests\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "from xml.etree.ElementTree import Element, SubElement, ElementTree, tostring \n",
    "from xml.dom.minidom import parseString "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b918360-a1d4-46e9-b470-39a4c5adaaaf",
   "metadata": {},
   "source": [
    "We clear the folders beforehand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c567d57c-0c30-445b-a67a-8833e7bf3646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Clears all files and subdirectories in the specified folder.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): Path to the folder to clear.\n",
    "    \"\"\"\n",
    "    if os.path.exists(folder_path):\n",
    "        # Remove all contents of the folder\n",
    "        for filename in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            try:\n",
    "                if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                    os.unlink(file_path)  # Remove file or symbolic link\n",
    "                elif os.path.isdir(file_path):\n",
    "                    shutil.rmtree(file_path)  # Remove directory\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to delete {file_path}. Reason: {e}\")\n",
    "    else:\n",
    "        # If folder doesn't exist, create it\n",
    "        os.makedirs(folder_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075e61ca-2ac6-4ac9-888b-fce440662479",
   "metadata": {},
   "source": [
    "Helper function to make PASCAL VOC-style XML annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a18cff47-6c2f-4d79-b8cd-3a3173aaeaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create Pascal-style XML annotations\n",
    "def create_pascal_xml(img_info, annotations, output_annotation_dir, categories):\n",
    "    \"\"\"\n",
    "    Generates a Pascal VOC-style XML file for a given image and its annotations.\n",
    "\n",
    "    Args:\n",
    "    - img_info (dict): Image metadata from COCO.\n",
    "    - annotations (list): List of annotations for the image.\n",
    "    - output_annotation_dir (str): Directory to save the XML file.\n",
    "    - categories (list): List of category names to include in the annotations.\n",
    "    \"\"\"\n",
    "    from xml.etree.ElementTree import Element, SubElement, tostring\n",
    "    from xml.dom.minidom import parseString\n",
    "    import os\n",
    "\n",
    "    xml_root = Element('annotation')\n",
    "    folder = SubElement(xml_root, 'folder')\n",
    "    folder.text = 'VOC_COCO'\n",
    "\n",
    "    filename = SubElement(xml_root, 'filename')\n",
    "    filename.text = img_info['file_name']\n",
    "\n",
    "    size = SubElement(xml_root, 'size')\n",
    "    SubElement(size, 'width').text = str(img_info['width'])\n",
    "    SubElement(size, 'height').text = str(img_info['height'])\n",
    "    SubElement(size, 'depth').text = '3'  # Assuming RGB images\n",
    "\n",
    "    for ann in annotations:\n",
    "        # Include only objects in the specified categories\n",
    "        cat_id = ann['category_id']\n",
    "        if cat_id not in id_categories.keys():\n",
    "            continue\n",
    "\n",
    "        obj = SubElement(xml_root, 'object')\n",
    "        name = SubElement(obj, 'name')\n",
    "        cat_name = id_categories[cat_id]\n",
    "        name.text = cat_name  # Category name from COCO annotation\n",
    "\n",
    "        # Default pose and truncated values\n",
    "        pose = SubElement(obj, 'pose')\n",
    "        pose.text = 'Unspecified'\n",
    "\n",
    "        truncated = SubElement(obj, 'truncated')\n",
    "        bbox = ann['bbox']  # COCO format: [xmin, ymin, width, height]\n",
    "        x_min = bbox[0]\n",
    "        y_min = bbox[1]\n",
    "        x_max = bbox[0] + bbox[2]\n",
    "        y_max = bbox[1] + bbox[3]\n",
    "        is_truncated = (\n",
    "            x_min < 0 or y_min < 0 or x_max > img_info['width'] or y_max > img_info['height']\n",
    "        )\n",
    "        truncated.text = '1' if is_truncated else '0'\n",
    "\n",
    "        # Bounding box\n",
    "        bndbox = SubElement(obj, 'bndbox')\n",
    "        SubElement(bndbox, 'xmin').text = str(max(0, int(x_min)))  # Clip to image boundaries\n",
    "        SubElement(bndbox, 'ymin').text = str(max(0, int(y_min)))\n",
    "        SubElement(bndbox, 'xmax').text = str(min(img_info['width'], int(x_max)))\n",
    "        SubElement(bndbox, 'ymax').text = str(min(img_info['height'], int(y_max)))\n",
    "\n",
    "    # If no relevant annotations, skip saving the XML\n",
    "    if not any(cat_name in categories for ann in annotations):\n",
    "        print(f\"Skipping XML generation for {img_info['file_name']} - no relevant annotations.\")\n",
    "        return\n",
    "\n",
    "    # Pretty format \n",
    "    asstring = tostring(xml_root, 'utf-8')\n",
    "    parsed_xml = parseString(asstring)\n",
    "    pretty_xml = parsed_xml.toprettyxml(indent=\"    \")\n",
    "\n",
    "    # Save XML\n",
    "    output_file = os.path.join(output_annotation_dir, f\"{os.path.splitext(img_info['file_name'])[0]}.xml\")\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write(pretty_xml)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1a5c56e7-86fb-463d-baa5-40a232d25fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading 2000 images of training data for category person\n",
    "# Paths\n",
    "keypoints_annotation_file = 'annotations/person_keypoints_train2017.json'  # Update with your COCO annotation file path\n",
    "annotation_file = 'annotations/instances_train2017.json'  # Update with your COCO annotation file path\n",
    "output_dir = 'coco_output'  # Folder to save downloaded images\n",
    "annotations_dir = os.path.join(output_dir, 'Annotations')\n",
    "sets_dir = os.path.join(output_dir, 'ImageSets', 'Main')\n",
    "images_dir = os.path.join(output_dir, 'JPEGImages')\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Number of images to sample\n",
    "num_images = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ea139a1-293a-4471-bc5b-7f047f06dfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=12.51s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# Load COCO annotations\n",
    "coco = COCO(annotation_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c051664-84b2-4f71-b01b-46439fbd2f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\n",
    "    'airplane', \n",
    "    'bicycle', \n",
    "    'bird', \n",
    "    'boat', \n",
    "    'bottle', \n",
    "    'bus',\n",
    "    'car',\n",
    "    'cat',\n",
    "    'chair',\n",
    "    'cow',\n",
    "    'dining table',\n",
    "    'dog', \n",
    "    'horse', \n",
    "    'motorcycle', \n",
    "    'person', \n",
    "    'potted plant',\n",
    "    'sheep',\n",
    "    'couch',\n",
    "    'train', \n",
    "    'TV',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a3394589-9710-4d86-bfd7-25f944f07e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_ids = {cat['name']: cat['id'] for cat in coco.loadCats(coco.getCatIds()) if cat['name'] in categories}\n",
    "id_categories = {v:k for (k,v) in category_ids.items()}\n",
    "# category_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "db9b7891-d963-4af6-b9f7-3bc65dbcde64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling for non-person categories\n",
    "num_images_per_category = 5\n",
    "person_instance_target = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1f945e-6f12-4682-b0d3-681d9dade3ee",
   "metadata": {},
   "source": [
    "## Clean all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7a717233-2dce-49a9-a993-c5aebeecbee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To freshly download (erase existing data) \n",
    "clear_folder(annotations_dir)\n",
    "clear_folder(sets_dir)\n",
    "clear_folder(images_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4c6d05-1e82-4f10-a7c0-20f12c23ab11",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "07ad7129-db26-4064-8352-481eeaf814e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:   0%|                                                           | 0/19 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing category: person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories: 100%|██████████████████████████████████████████████████| 19/19 [00:00<00:00, 31.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 5 images to meet 10 'person' instances.\n",
      "Processing category: bicycle\n",
      "Selected 5 unique images for category bicycle.\n",
      "Processing category: car\n",
      "Selected 5 unique images for category car.\n",
      "Processing category: motorcycle\n",
      "Selected 5 unique images for category motorcycle.\n",
      "Processing category: airplane\n",
      "Selected 5 unique images for category airplane.\n",
      "Processing category: bus\n",
      "Selected 5 unique images for category bus.\n",
      "Processing category: train\n",
      "Selected 5 unique images for category train.\n",
      "Processing category: boat\n",
      "Selected 5 unique images for category boat.\n",
      "Processing category: bird\n",
      "Selected 5 unique images for category bird.\n",
      "Processing category: cat\n",
      "Selected 5 unique images for category cat.\n",
      "Processing category: dog\n",
      "Selected 5 unique images for category dog.\n",
      "Processing category: horse\n",
      "Selected 5 unique images for category horse.\n",
      "Processing category: sheep\n",
      "Selected 5 unique images for category sheep.\n",
      "Processing category: cow\n",
      "Selected 5 unique images for category cow.\n",
      "Processing category: bottle\n",
      "Selected 5 unique images for category bottle.\n",
      "Processing category: chair\n",
      "Selected 5 unique images for category chair.\n",
      "Processing category: couch\n",
      "Selected 5 unique images for category couch.\n",
      "Processing category: potted plant\n",
      "Selected 5 unique images for category potted plant.\n",
      "Processing category: dining table\n",
      "Selected 5 unique images for category dining table.\n",
      "Annotations collected for 95 images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████████████████████████████████████████████████| 95/95 [00:15<00:00,  6.20it/s]\n",
      "Writing ImageSets: 100%|███████████████████████████████████████████████████| 95/95 [00:00<00:00, 43642.81it/s]\n",
      "Writing train.txt: 100%|██████████████████████████████████████████████████| 95/95 [00:00<00:00, 539186.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageSets folder created at coco_output/ImageSets/Main.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_images = set()\n",
    "# Track globally selected image IDs to avoid duplicates\n",
    "globally_selected_image_ids = set()\n",
    "random.seed(429)\n",
    "\n",
    "# Prepare data structures\n",
    "train_txt_path = os.path.join(sets_dir, \"train.txt\")\n",
    "category_txt_files = {category: open(os.path.join(sets_dir, f\"{category}_train.txt\"), \"w\") for category in categories}\n",
    "positive_samples = {category: set() for category in categories}\n",
    "annotations_by_image = {}\n",
    "\n",
    "# Process each category\n",
    "for category, category_id in tqdm(category_ids.items(), desc=\"Processing categories\"):\n",
    "    print(f\"Processing category: {category}\")\n",
    "\n",
    "    # Handle 'person' category separately for 4100 instances\n",
    "    if category == 'person':\n",
    "        instance_target = person_instance_target\n",
    "        instance_count = 0\n",
    "        selected_image_ids = []\n",
    "        image_ids = coco.getImgIds(catIds=[category_id])\n",
    "        random.shuffle(image_ids)\n",
    "\n",
    "        # Collect images until the instance target is reached\n",
    "        for img_id in image_ids:\n",
    "            if img_id in globally_selected_image_ids:\n",
    "                continue  # Skip already selected image IDs\n",
    "\n",
    "            ann_ids = coco.getAnnIds(imgIds=[img_id], catIds=[category_id])\n",
    "            person_count = len(ann_ids)\n",
    "            if instance_count + person_count <= instance_target:\n",
    "                selected_image_ids.append(img_id)\n",
    "                globally_selected_image_ids.add(img_id)  # Mark as globally selected\n",
    "                instance_count += person_count\n",
    "            if len(selected_image_ids) >= instance_target:  # Ensure no oversampling\n",
    "                break\n",
    "\n",
    "        print(f\"Selected {len(selected_image_ids)} images to meet {instance_target} 'person' instances.\")\n",
    "    else:\n",
    "        # Default behavior for other categories\n",
    "        image_ids = coco.getImgIds(catIds=[category_id])\n",
    "        random.shuffle(image_ids)\n",
    "\n",
    "        selected_image_ids = []\n",
    "        for img_id in image_ids:\n",
    "            if img_id in globally_selected_image_ids:\n",
    "                continue  # Skip already selected image IDs\n",
    "\n",
    "            selected_image_ids.append(img_id)\n",
    "            globally_selected_image_ids.add(img_id)  # Mark as globally selected\n",
    "\n",
    "            if len(selected_image_ids) >= num_images_per_category:  # Stop once we have enough\n",
    "                break\n",
    "\n",
    "        print(f\"Selected {len(selected_image_ids)} unique images for category {category}.\")\n",
    "\n",
    "\n",
    "    # Collect annotations for each selected image\n",
    "    for img_id in selected_image_ids:\n",
    "        in_this_image = coco.loadAnns(coco.getAnnIds(imgIds=[img_id]))\n",
    "        annotations_by_image[img_id] = in_this_image\n",
    "\n",
    "        # Update positive samples\n",
    "        img_filename = os.path.splitext(coco.loadImgs(img_id)[0]['file_name'])[0]\n",
    "        for ann in in_this_image: \n",
    "            cat_id = ann['category_id']\n",
    "            if cat_id in id_categories.keys():\n",
    "                positive_samples[id_categories[cat_id]].add(img_filename)\n",
    "\n",
    "print(f\"Annotations collected for {len(annotations_by_image)} images.\")\n",
    "\n",
    "# Download images and create XML annotations\n",
    "for img_id, annotations in tqdm(annotations_by_image.items(), desc=\"Processing images\"):\n",
    "    img_info = coco.loadImgs(img_id)[0]\n",
    "    img_filename = os.path.splitext(img_info['file_name'])[0]\n",
    "    img_filepath = os.path.join(images_dir, img_info['file_name'])\n",
    "    all_images.add(img_filename)\n",
    "\n",
    "    # Download image if it doesn't already exist\n",
    "    if not os.path.exists(img_filepath):\n",
    "        try:\n",
    "            response = requests.get(img_info['coco_url'], stream=True, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            with open(img_filepath, 'wb') as f:\n",
    "                for chunk in response.iter_content(1024):\n",
    "                    f.write(chunk)\n",
    "            # Create Pascal VOC XML annotation\n",
    "            create_pascal_xml(img_info, annotations, annotations_dir, categories)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Failed to download {img_info['file_name']}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# Write ImageSets files\n",
    "sorted_imgs = sorted(all_images)\n",
    "for img_filename in tqdm(sorted_imgs, desc=\"Writing ImageSets\"):\n",
    "    for category in categories:\n",
    "        # Label is 1 if image is in positive samples for the category, otherwise -1\n",
    "        label = \"1\" if img_filename in positive_samples[category] else \"-1\"\n",
    "        category_txt_files[category].write(f\"{img_filename} {label}\\n\")\n",
    "\n",
    "# Write train.txt\n",
    "with open(train_txt_path, \"w\") as train_file:\n",
    "    for img_filename in tqdm(sorted_imgs, desc=\"Writing train.txt\"):\n",
    "        train_file.write(f\"{img_filename}\\n\")\n",
    "\n",
    "# Close category-specific text files\n",
    "for file in category_txt_files.values():\n",
    "    file.close()\n",
    "\n",
    "print(f\"ImageSets folder created at {sets_dir}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d4fc60-7a06-4ffc-ba6e-4a5eaba35687",
   "metadata": {},
   "source": [
    "### Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5f8b21a0-6c60-40c7-b9ca-845903f117a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'license': 6,\n",
       "  'file_name': '000000010948.jpg',\n",
       "  'coco_url': 'http://images.cocodataset.org/train2017/000000010948.jpg',\n",
       "  'height': 376,\n",
       "  'width': 500,\n",
       "  'date_captured': '2013-11-22 00:28:09',\n",
       "  'flickr_url': 'http://farm1.staticflickr.com/121/305482790_d063783500_z.jpg',\n",
       "  'id': 10948}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco.loadImgs(ids=[10948])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "63560ce8-ebe5-4db0-b460-7d044635db94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[47931,\n",
       " 99444,\n",
       " 200424,\n",
       " 235251,\n",
       " 1334779,\n",
       " 1510594,\n",
       " 1629956,\n",
       " 1973648,\n",
       " 1974781,\n",
       " 1974896,\n",
       " 1991653]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco.getAnnIds(imgIds=[10948])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "acac28b4-33a0-49ec-86fc-dcf2f4ddfb9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17, 63, 1, 1, 2, 47, 75, 75, 75, 75, 85]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[a['category_id'] for a in coco.loadAnns([\n",
    "     47931,\n",
    "     99444,\n",
    "     200424,\n",
    "     235251,\n",
    "     1334779,\n",
    "     1510594,\n",
    "     1629956,\n",
    "     1973648,\n",
    "     1974781,\n",
    "     1974896,\n",
    "     1991653\n",
    "])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "372a5fe9-fb8a-459b-a29b-c9c61224b962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'person': 1,\n",
       " 'bicycle': 2,\n",
       " 'car': 3,\n",
       " 'motorcycle': 4,\n",
       " 'airplane': 5,\n",
       " 'bus': 6,\n",
       " 'train': 7,\n",
       " 'boat': 9,\n",
       " 'bird': 16,\n",
       " 'cat': 17,\n",
       " 'dog': 18,\n",
       " 'horse': 19,\n",
       " 'sheep': 20,\n",
       " 'cow': 21,\n",
       " 'bottle': 44,\n",
       " 'chair': 62,\n",
       " 'couch': 63,\n",
       " 'potted plant': 64,\n",
       " 'dining table': 67}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "321adefd-dbca-4a4f-a1a2-fcd0cfdc5f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'segmentation': [[321.99,\n",
       "    258.37,\n",
       "    317.94,\n",
       "    252.85,\n",
       "    318.68,\n",
       "    248.07,\n",
       "    320.89,\n",
       "    242.18,\n",
       "    324.2,\n",
       "    239.98,\n",
       "    330.82,\n",
       "    238.5,\n",
       "    335.6,\n",
       "    233.72,\n",
       "    342.22,\n",
       "    233.72,\n",
       "    348.1,\n",
       "    234.09,\n",
       "    351.04,\n",
       "    235.19,\n",
       "    348.47,\n",
       "    229.68,\n",
       "    356.56,\n",
       "    229.68,\n",
       "    359.5,\n",
       "    231.52,\n",
       "    366.49,\n",
       "    230.05,\n",
       "    370.17,\n",
       "    230.41,\n",
       "    372.74,\n",
       "    234.09,\n",
       "    371.27,\n",
       "    239.24,\n",
       "    373.11,\n",
       "    244.76,\n",
       "    372.38,\n",
       "    246.96,\n",
       "    371.64,\n",
       "    248.8,\n",
       "    372.01,\n",
       "    252.85,\n",
       "    372.01,\n",
       "    256.16,\n",
       "    375.32,\n",
       "    259.1,\n",
       "    375.69,\n",
       "    262.04,\n",
       "    372.38,\n",
       "    263.15,\n",
       "    368.33,\n",
       "    263.88,\n",
       "    365.02,\n",
       "    265.72,\n",
       "    362.08,\n",
       "    264.99,\n",
       "    360.97,\n",
       "    263.15,\n",
       "    356.93,\n",
       "    263.88,\n",
       "    348.47,\n",
       "    265.35,\n",
       "    342.59,\n",
       "    266.09,\n",
       "    340.01,\n",
       "    267.56,\n",
       "    334.86,\n",
       "    267.93,\n",
       "    330.82,\n",
       "    266.82,\n",
       "    326.04,\n",
       "    264.99,\n",
       "    324.2,\n",
       "    263.51,\n",
       "    322.36,\n",
       "    260.2,\n",
       "    320.15,\n",
       "    258.0]],\n",
       "  'area': 1648.8485,\n",
       "  'iscrowd': 0,\n",
       "  'image_id': 10948,\n",
       "  'bbox': [317.94, 229.68, 57.75, 38.25],\n",
       "  'category_id': 17,\n",
       "  'id': 47931}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco.loadAnns(47931)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cos429",
   "language": "python",
   "name": "cos429"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
